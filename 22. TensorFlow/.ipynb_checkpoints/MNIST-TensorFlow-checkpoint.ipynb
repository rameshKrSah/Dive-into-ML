{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing MNIST datset from sklearn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "custom_data_home = '/Users/abhishek/Desktop/Dive-Into-ML/ML/22. TensorFlow'\n",
    "mnist1 = fetch_mldata('MNIST original', data_home=custom_data_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Import MNIST dataset from tensorflow\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x18161931d0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1051c7ac8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1051c7ba8>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset contains total of 70,000 images of shape 28 * 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Multiclass from 0 to 9\n",
    "## One hot encoded labels\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADQRF+ICjCDwT1X00+72AlohAXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25ced278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = mnist.train.images[412]\n",
    "first_image = np.array(first_image, dtype ='float').reshape((28,28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of units in each layer\n",
    "\n",
    "# Input layer contains 784 units because each data is 784 sized array\n",
    "n_input = 784\n",
    "\n",
    "# Randomly decided number of units in hidden layers (chose in the order of n_input like something in between 100&1000)\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# Output layer is one hot encoded for the 10 categories\n",
    "n_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initilised random weights and biases\n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU (Rectified Linear Unit) Activation Function** :\n",
    "$$ R(z) = max(0,z)$$\n",
    "\n",
    "* The ReLU is half rectified (from bottom). f(z) is zero when z is less than zero and f(z) is equal to z when z is above or equal to zero.\n",
    "* Range: [ 0 to infinity)\n",
    "* The function and its derivative both are monotonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(x, weights, biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x, weights['h1']), biases['h1'])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)   #We are using relu as activation function \n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1, weights['h2']), biases['h2'])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2, weights['out']), biases['out'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])\n",
    "pred = forward_propagation(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimiser searchs for all the variables where \"Trainable = True\" and find the gradient with respect to them and change their values accordingly to optimize the cost.\n",
    "* Finds the derivative(slope) values & change the variable values as per the learning rate and the slopes once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialise the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24527.9869936\n",
      "4781.34356751\n",
      "2791.35932008\n",
      "1852.41344977\n",
      "1335.97847667\n",
      "1301.16174445\n",
      "1090.45728788\n",
      "1130.9774897\n",
      "973.560108405\n",
      "782.566111002\n",
      "669.119898995\n",
      "606.30710042\n",
      "618.618930011\n",
      "605.69630502\n",
      "486.138104753\n",
      "466.56906859\n",
      "412.689092864\n",
      "385.436124445\n",
      "380.050660788\n",
      "300.97098168\n",
      "322.246121947\n",
      "301.874636015\n",
      "295.191042372\n",
      "238.705210696\n",
      "226.943479806\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Running multiple iterations of Optimizer\n",
    "for iter in range(25):\n",
    "    # Batch Gradient Descent\n",
    "    num_batches = int(mnist.train.num_examples / batch_size)\n",
    "    total_cost = 0  #Total cost in a batch\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost, optimize], feed_dict = {x : batch_x, y: batch_y})\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9618"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1)  ## tf.argmax will find the index at which the maximum is present \n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "\n",
    "predictions, correct_predictions =  sess.run([predictions, correct_predictions], \n",
    "                                                   feed_dict = {x: mnist.test.images, y: mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "* Accuracy of our algorithm will not always improve as we increase the number of iterations. It can go up or down depending on the learning rate \n",
    "* Benefit of calling optimize in multiple batches is that it will be faster to reach the results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
