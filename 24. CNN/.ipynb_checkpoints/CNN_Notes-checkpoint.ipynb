{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem in Handling Images:\n",
    "* Problem with treating each pixel individually for image classification is that Some pixels combined together generate patterns which are not recognized if treated separately.\n",
    "\n",
    "### CNN\n",
    "* A Convolution Neural Network processes images - a group of pixels at a time.\n",
    "\n",
    "* Convolutional neural networks are widely used for\n",
    "    * image and video recognition \n",
    "    * recommender systems \n",
    "    * natural language processing \n",
    "\n",
    "* k*k filter in each convolutional unit is passed over entire image. \n",
    "\n",
    "* Each k*k filter in a convolutional unit is used to identify a pattern anywhere in image. \n",
    "\n",
    "* Consider a K x K filter applied on a K x K part of the image. Let pij be the pixels in the image part and wij be the weights in the filter. Then the final value given as output by the unit applying the filter will be:\n",
    "    $$ \\sum_{i=0}^{i = k-1}  \\sum_{j = 0}^{j = k-1}  (p_{ij} *  w_{ij})  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride and Padding\n",
    "* We shouldnâ€™t  have stride value greater than K, the filter dimension because it will leave gaps in between two parts of the image to be process, and we might thus lose valuable information. \n",
    "* Increasing the size of stride will - Reduce output size.\n",
    "* Padding\n",
    "    1. Valid\n",
    "    2. Same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels\n",
    "* Channels for coloured images refers to RGB values for colour of image. \n",
    "* The channel value for 2nd convolutional layer will be the number of Convolutional units in 1st layer. \n",
    "* E.g. For an image with 28*28 pixels and 32 convolutional units , output is of shape(consider same padding): 28*28*32 \n",
    "    * For same padding output image is of same shape as input so, it would be 28 \\* 28 . \n",
    "    * Since there are 32 convolution units , output would have 32 images of 28 * 28 \n",
    "    * thus output has dimension 28\\*28\\*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "* The purpose of pooling is to reduce the size of image.\n",
    "* Pooling layers are applied: After convolution layer.\n",
    "* E.g. If our image size is 18x18 and pool size 3x3, then the dimensions of the output from the pooling layer will be 6x6.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Flow in CNN\n",
    "* The output of Convolutional layer will be Transformed image in lower resolution.\n",
    "* The number of units in the output layer of a CNN is: The number of outputs/class labels for the dataset. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
