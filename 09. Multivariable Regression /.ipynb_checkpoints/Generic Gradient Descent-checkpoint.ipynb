{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient(points, learning_rate, m):\n",
    "    \n",
    "    row_count = len(points)\n",
    "    col_count = len(points[0])\n",
    "    \n",
    "    m_slope = [0 for i in range(col_count)]\n",
    "    N = row_count\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = points[i]\n",
    "        y = points[i][col_count-1]\n",
    "            \n",
    "        sum = 0\n",
    "        for k in range(col_count-1):\n",
    "            sum += m[k] * x[k] \n",
    "        \n",
    "        for j in range(col_count-1):    \n",
    "            m_slope[j] += (-2/N) * (y- sum) * x[j]\n",
    "    \n",
    "    \n",
    "    new_m = [0 for i in range(col_count-1)]\n",
    "    for j in range(col_count-1):\n",
    "        new_m[j] = m[j] - learning_rate * m_slope[j]\n",
    "        \n",
    "    return new_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(points, m):\n",
    "    N = len(points)\n",
    "    col_count = len(points[0])\n",
    "    cost = 0\n",
    "    for i in range(N):\n",
    "        x = points[i]\n",
    "        y = points[i][col_count-1]\n",
    "            \n",
    "        sum = 0\n",
    "        for k in range(col_count-1):\n",
    "            sum += m[k] * x[k]\n",
    "        \n",
    "        cost += (1/N) * ((y-sum)**2)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gd(points, learning_rate, num_iterations):\n",
    "    m = [ 0 for i in range(len(points[0])-1)]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(points, learning_rate, m) \n",
    "        print(i, \"Cost: \", cost(points,m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = np.genfromtxt(\"boston_x_y_train.csv\", delimiter = \",\")\n",
    "    \n",
    "    row_count = len(data)\n",
    "    col_count = len(data[0])\n",
    "    \n",
    "    n_data = [[0 for j in range(col_count+1)]for i in range(row_count)]\n",
    "\n",
    "    for i in range(row_count):\n",
    "        for j in range(col_count-1):\n",
    "            n_data[i][j] = data[i][j]\n",
    "        \n",
    "        n_data[i][col_count-1] = 1\n",
    "        n_data[i][col_count] =  data[i][col_count-1]\n",
    "    \n",
    "    new_data = np.array(n_data)    \n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(points,m):\n",
    "    y = [0 for i in range(len(points))]\n",
    "    \n",
    "    for i in range(len(points)):\n",
    "        x = points[i]\n",
    "        y[i] = 0\n",
    "        for j in range(len(points[0])-1):\n",
    "            y[i] += m[j] * x[j]\n",
    "        \n",
    "        y[i] += m[j] \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(data):\n",
    "    x_scaled = preprocessing.scale(data)\n",
    "    \n",
    "    n_data = [[0 for j in range(len(data[0]))]for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])-2):\n",
    "            n_data[i][j] = x_scaled[i][j]\n",
    "        n_data[i][len(data[0])-2] = data[i][len(data[0])-2]\n",
    "        n_data[i][len(data[0])-1] = data[i][len(data[0])-1]\n",
    "        \n",
    "    return n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    data = load_data()\n",
    "    \n",
    "#     print(pd.DataFrame(preprocessing.scale(data)).describe())\n",
    "    \n",
    "    \n",
    "    data_scaled = scale(data)\n",
    "    \n",
    "#     print(pd.DataFrame(preprocessing.scale(data_scaled)).describe())\n",
    "    \n",
    "    \n",
    "    learning_rate =  0.1\n",
    "    num_iterations =  100\n",
    "    \n",
    "    m = gd(data_scaled, learning_rate, num_iterations)\n",
    "    \n",
    "    print(\"Set of m: \")\n",
    "    for x in m:\n",
    "        print(x)\n",
    "    \n",
    "    test_data = np.genfromtxt(\"boston_x_test.csv\", delimiter = \",\")\n",
    "    test_data_scaled = preprocessing.scale(test_data)\n",
    "    \n",
    "#     print(pd.DataFrame(preprocessing.scale(test_data_scaled)).describe())\n",
    "    \n",
    "    y = predict(test_data_scaled,m)\n",
    "\n",
    "    np.savetxt(\"result.csv\",y, fmt= '%0.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  372.640228249\n",
      "1 Cost:  246.080684499\n",
      "2 Cost:  166.314625295\n",
      "3 Cost:  115.50146384\n",
      "4 Cost:  83.0587141243\n",
      "5 Cost:  62.3083509347\n",
      "6 Cost:  49.0104149274\n",
      "7 Cost:  40.4681913201\n",
      "8 Cost:  34.9643575745\n",
      "9 Cost:  31.40411193\n",
      "10 Cost:  29.0888396195\n",
      "11 Cost:  27.5723391448\n",
      "12 Cost:  26.5693719176\n",
      "13 Cost:  25.8974284289\n",
      "14 Cost:  25.4396109945\n",
      "15 Cost:  25.1209566428\n",
      "16 Cost:  24.8933227757\n",
      "17 Cost:  24.7257327939\n",
      "18 Cost:  24.5982057181\n",
      "19 Cost:  24.4978103359\n",
      "20 Cost:  24.4161404895\n",
      "21 Cost:  24.3476987184\n",
      "22 Cost:  24.2888607704\n",
      "23 Cost:  24.2372117322\n",
      "24 Cost:  24.1911200201\n",
      "25 Cost:  24.1494636905\n",
      "26 Cost:  24.1114543471\n",
      "27 Cost:  24.0765236215\n",
      "28 Cost:  24.0442498035\n",
      "29 Cost:  24.0143102581\n",
      "30 Cost:  23.9864504249\n",
      "31 Cost:  23.9604634982\n",
      "32 Cost:  23.9361770008\n",
      "33 Cost:  23.9134438198\n",
      "34 Cost:  23.892136141\n",
      "35 Cost:  23.8721412754\n",
      "36 Cost:  23.8533587287\n",
      "37 Cost:  23.8356980951\n",
      "38 Cost:  23.8190775015\n",
      "39 Cost:  23.8034224269\n",
      "40 Cost:  23.7886647798\n",
      "41 Cost:  23.7747421583\n",
      "42 Cost:  23.7615972403\n",
      "43 Cost:  23.749177272\n",
      "44 Cost:  23.7374336292\n",
      "45 Cost:  23.7263214365\n",
      "46 Cost:  23.7157992327\n",
      "47 Cost:  23.7058286741\n",
      "48 Cost:  23.6963742691\n",
      "49 Cost:  23.6874031398\n",
      "50 Cost:  23.6788848073\n",
      "51 Cost:  23.6707909969\n",
      "52 Cost:  23.6630954613\n",
      "53 Cost:  23.65577382\n",
      "54 Cost:  23.6488034124\n",
      "55 Cost:  23.6421631641\n",
      "56 Cost:  23.6358334647\n",
      "57 Cost:  23.6297960555\n",
      "58 Cost:  23.6240339267\n",
      "59 Cost:  23.6185312236\n",
      "60 Cost:  23.61327316\n",
      "61 Cost:  23.6082459385\n",
      "62 Cost:  23.603436678\n",
      "63 Cost:  23.598833346\n",
      "64 Cost:  23.5944246967\n",
      "65 Cost:  23.5902002146\n",
      "66 Cost:  23.586150061\n",
      "67 Cost:  23.5822650263\n",
      "68 Cost:  23.578536485\n",
      "69 Cost:  23.5749563541\n",
      "70 Cost:  23.5715170553\n",
      "71 Cost:  23.5682114795\n",
      "72 Cost:  23.5650329542\n",
      "73 Cost:  23.5619752134\n",
      "74 Cost:  23.5590323694\n",
      "75 Cost:  23.5561988874\n",
      "76 Cost:  23.5534695611\n",
      "77 Cost:  23.5508394905\n",
      "78 Cost:  23.5483040615\n",
      "79 Cost:  23.5458589269\n",
      "80 Cost:  23.5434999884\n",
      "81 Cost:  23.5412233803\n",
      "82 Cost:  23.5390254542\n",
      "83 Cost:  23.5369027649\n",
      "84 Cost:  23.5348520572\n",
      "85 Cost:  23.5328702535\n",
      "86 Cost:  23.5309544426\n",
      "87 Cost:  23.5291018694\n",
      "88 Cost:  23.5273099242\n",
      "89 Cost:  23.5255761346\n",
      "90 Cost:  23.5238981561\n",
      "91 Cost:  23.5222737647\n",
      "92 Cost:  23.5207008492\n",
      "93 Cost:  23.5191774046\n",
      "94 Cost:  23.5177015253\n",
      "95 Cost:  23.5162713995\n",
      "96 Cost:  23.5148853033\n",
      "97 Cost:  23.5135415957\n",
      "98 Cost:  23.5122387136\n",
      "99 Cost:  23.5109751674\n",
      "Set of m: \n",
      "-0.958992816859\n",
      "0.641767006538\n",
      "-0.215344159455\n",
      "0.842385144\n",
      "-2.07247798373\n",
      "2.39725326599\n",
      "0.0927197896371\n",
      "-2.98067506601\n",
      "2.05474029095\n",
      "-1.15649696588\n",
      "-2.21895462142\n",
      "0.588816591037\n",
      "-4.31356879503\n",
      "22.6094986761\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
