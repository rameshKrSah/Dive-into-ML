{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527927850.476831"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our own list of some block words to be avoided  \n",
    "block_words = ['newsgroups', 'xref', 'path', 'from', 'subject', 'sender', 'organisation', 'apr','gmt', 'last','better','never','every','even','two','good','used','first','need','going','must','really','might','well','without','made','give','look','try','far','less','seem','new','make','many','way','since','using','take','help','thanks','send','free','may','see','much','want','find','would','one','like','get','use','also','could','say','us','go','please','said','set','got','sure','come','lot','seems','able','anything','put', '--', '|>', '>>', '93', 'xref', 'cantaloupe.srv.cs.cmu.edu', '20', '16', \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", '21', '19', '10', '17', '24', 'reply-to:', 'thu', 'nntp-posting-host:', 're:','25''18'\"i'd\"'>i''22''fri,''23''>the','references:','xref:','sender:','writes:','1993','organization:']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a.tar.gz', <http.client.HTTPMessage at 0x10d600fd0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\", \"a.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open(\"a.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk.politics.mideast',\n",
       " 'rec.autos',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'alt.atheism',\n",
       " 'rec.sport.baseball',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.med',\n",
       " 'talk.politics.misc',\n",
       " 'rec.motorcycles',\n",
       " 'comp.windows.x',\n",
       " 'comp.graphics',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'sci.electronics',\n",
       " 'talk.politics.guns',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'misc.forsale',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Make a list of the folders in the dataset\n",
    "directory = [f for f in os.listdir('./20_newsgroups') if not f.startswith('.')]\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for i in range(len(directory)):\n",
    "    ##Create a list of files in the given dictionary \n",
    "    files = os.listdir('./20_newsgroups/' + directory[i])\n",
    " \n",
    "    for j in range(len(files)):\n",
    "        ##Path of each file \n",
    "        path = './20_newsgroups/' + directory[i] + '/' + files[j]\n",
    "        \n",
    "        ##open the file and read it\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        \n",
    "        for word in text.split():\n",
    "            \n",
    "            ## If word doesnt contain any special character then create the dictionary\n",
    "            if len(word) != 1:  \n",
    "                \n",
    "                ##Check if word is a non stop word or non block word(we have created) only then proceed\n",
    "                if not word.lower() in stop_words:\n",
    "                    if not word.lower() in block_words:     \n",
    "                        ##If word is already in dictionary then we just increment its frequency by 1\n",
    "                        if vocab.get(word.lower()) != None:\n",
    "                            vocab[word.lower()] += 1\n",
    "\n",
    "                        ##If word is not in dictionary then we put that word in our dictinary by making its frequnecy 1\n",
    "                        else:\n",
    "                            vocab[word.lower()] = 1\n",
    "            \n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_vocab = sorted(vocab.items(), key= operator.itemgetter(1), reverse= True)\n",
    "# sorted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary containing the most occuring k-words.\n",
    "kvocab={}\n",
    "\n",
    "# Frequency of 1000th most occured word\n",
    "z = sorted_vocab[2000][1]\n",
    "\n",
    "for x in sorted_vocab:\n",
    "    kvocab[x[0]] = x[1]\n",
    "    \n",
    "    if x[1] <= z:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subject:', 20486),\n",
       " ('from:', 20417),\n",
       " ('date:', 20137),\n",
       " ('newsgroups:', 20081),\n",
       " ('message-id:', 20050),\n",
       " ('lines:', 20042),\n",
       " ('path:', 20029),\n",
       " ('article', 12108),\n",
       " ('people', 8415),\n",
       " ('university', 8203),\n",
       " ('know', 7695),\n",
       " ('think', 7205),\n",
       " (\"i'm\", 5823),\n",
       " ('distribution:', 4406),\n",
       " ('time', 4336),\n",
       " ('it.', 4185),\n",
       " ('anyone', 3976),\n",
       " ('world', 3602),\n",
       " ('right', 3326),\n",
       " ('believe', 3309),\n",
       " ('still', 3290),\n",
       " ('something', 3190),\n",
       " ('computer', 3157),\n",
       " ('system', 3137),\n",
       " (\"i've\", 3114),\n",
       " ('15', 2881),\n",
       " ('god', 2881),\n",
       " ('back', 2840),\n",
       " ('news', 2836),\n",
       " (\"can't\", 2836),\n",
       " ('state', 2787),\n",
       " ('work', 2692),\n",
       " ('>in', 2610),\n",
       " ('someone', 2610),\n",
       " ('government', 2534),\n",
       " ('problem', 2528),\n",
       " ('23', 2522),\n",
       " ('another', 2516),\n",
       " ('read', 2516),\n",
       " ('usa', 2496),\n",
       " ('information', 2480),\n",
       " ('>the', 2452),\n",
       " ('number', 2424),\n",
       " (\"that's\", 2382),\n",
       " ('things', 2378),\n",
       " ('part', 2323),\n",
       " ('fri,', 2307),\n",
       " ('point', 2297),\n",
       " ('little', 2294),\n",
       " ('22', 2284),\n",
       " ('windows', 2265),\n",
       " ('>i', 2253),\n",
       " ('tue,', 2241),\n",
       " ('file', 2208),\n",
       " ('data', 2155),\n",
       " ('question', 2126),\n",
       " ('probably', 2112),\n",
       " ('years', 2106),\n",
       " ('different', 2100),\n",
       " ('available', 2095),\n",
       " ('space', 2079),\n",
       " ('(usenet', 2079),\n",
       " ('it,', 2073),\n",
       " ('around', 2072),\n",
       " ('long', 2053),\n",
       " ('tell', 2048),\n",
       " ('least', 2006),\n",
       " ('best', 1997),\n",
       " ('program', 1995),\n",
       " ('software', 1976),\n",
       " ('public', 1961),\n",
       " ('power', 1958),\n",
       " ('thu,', 1883),\n",
       " ('thing', 1875),\n",
       " ('drive', 1870),\n",
       " ('run', 1869),\n",
       " ('support', 1864),\n",
       " ('however,', 1826),\n",
       " (\"i'd\", 1825),\n",
       " ('18', 1804),\n",
       " ('rather', 1801),\n",
       " ('enough', 1792),\n",
       " ('case', 1791),\n",
       " ('hard', 1786),\n",
       " ('keep', 1770),\n",
       " ('fact', 1767),\n",
       " ('25', 1758),\n",
       " ('let', 1757),\n",
       " ('science', 1753),\n",
       " ('called', 1751),\n",
       " ('great', 1742),\n",
       " ('...', 1738),\n",
       " ('call', 1725),\n",
       " ('looking', 1709),\n",
       " ('mon,', 1690),\n",
       " ('found', 1683),\n",
       " ('real', 1676),\n",
       " ('nothing', 1671),\n",
       " ('26', 1661),\n",
       " ('quite', 1634)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocab[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = list(kvocab.keys())\n",
    "\n",
    "## Create a Dataframe containing features_list as columns \n",
    "df = pd.DataFrame(columns = features_list)\n",
    "\n",
    "\n",
    "## Filling the x_train values in dataframe \n",
    "\n",
    "for i in range(len(directory)):\n",
    "    ##Create a list of files in the given dictionary \n",
    "    files = os.listdir('./20_newsgroups/' + directory[i])\n",
    " \n",
    "    for j in range(len(files)):\n",
    "        ##Insert a row at the end of Dataframe with all zeros\n",
    "        df.loc[len(df)] = np.zeros(len(features_list))\n",
    "        \n",
    "        ##Path of each file \n",
    "        path = './20_newsgroups/' + directory[i] + '/' + files[j]\n",
    "        \n",
    "        ##open the file and read it\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        \n",
    "        \n",
    "        for word in text.split():\n",
    "            if word.lower() in features_list:\n",
    "                df[word.lower()][len(df)-1] += 1\n",
    "                \n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 2001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making the 2d array of x\n",
    "x = df.values\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating  y array containing labels for classification \n",
    "\n",
    "y = []\n",
    "\n",
    "for i in range(len(directory)):\n",
    "    ##Create a list of files in the given dictionary \n",
    "    files = os.listdir('./20_newsgroups/' + directory[i])\n",
    " \n",
    "    for j in range(len(files)):\n",
    "        y.append(i)\n",
    "\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Multinomial Naive Bayes from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87450823498032937, 0.83940000000000003)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "train_score = clf.score(x_train, y_train)\n",
    "test_score = clf.score(x_test, y_test)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198265.5856180191"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Multinomial Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    \n",
    "    ## features list from x\n",
    "#     features = list(x_train)\n",
    "    \n",
    "    ## dictionary containing the count of words\n",
    "    count = {}\n",
    "    \n",
    "    count[\"total_data\"] = len(y_train)\n",
    "    \n",
    "    ## set of all classes \n",
    "    set_class = set(y_train)\n",
    "            \n",
    "    for current_class in set_class:\n",
    "        count[current_class] = {}\n",
    "    \n",
    "        current_class_rows = (y_train == current_class)\n",
    "        \n",
    "        x_train_current = x_train[current_class_rows]\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        \n",
    "        sumCount = 0\n",
    "        for x in features_list:\n",
    "            count[current_class][x] = x_train_current[x].sum()\n",
    "            sumCount =+ count[current_class][x]\n",
    "        \n",
    "        count[current_class][\"totalCount\"] = sumCount\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary, row, current_class):\n",
    "    ## class_prob = probability of the current class = (no of documents having class as current_class)/ (total number of documents)\n",
    "    class_prob = np.log(dictionary[current_class][\"total_count\"])-np.log(dictionary[\"total_data\"])\n",
    "    total_prob = class_prob\n",
    "    \n",
    "    \n",
    "    for i in len(row):\n",
    "        word_count = dictionary[current_class][i] + 1     \n",
    "        total_count = dictionary[current_class]['total_count'] + len(row)\n",
    "        ## Add 1 to numerator and len(row) in denominator for laplace correction\n",
    "        \n",
    "        word_prob = np.log(word_count) - np.log(total_count)\n",
    "        \n",
    "        total_prob += word_prob\n",
    "        \n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(row, dictionary):\n",
    "    classes = dictionary.keys()\n",
    "    \n",
    "    best_prob = -1000\n",
    "    best_class = -1\n",
    "    first_iter = True\n",
    "    \n",
    "    for current_class in classes:\n",
    "        if(current_class == \"total_data\"):\n",
    "            continue\n",
    "        prob_current_class = probability(dictionary, row, current_class)\n",
    "        \n",
    "        if(first_iter or prob_current_class > best_prob):\n",
    "            best_prob = prob_current_class\n",
    "            best_class = current_class\n",
    "        \n",
    "        first_iter = False\n",
    "        \n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_test, dictionary):\n",
    "    y_pred_self = []\n",
    "    \n",
    "    for j in len(x_test):\n",
    "        \n",
    "        pred_class = predictSinglePoint(x_test[j,:], dictionary) \n",
    "        y_pred_self.append(pred_class)\n",
    "    \n",
    "    return y_pred_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-292db2996089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m##Predicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-25b55593ac3a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msumCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_current\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0msumCount\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "## Training model \n",
    "dictionary = fit(x_train, y_train)\n",
    "\n",
    "##Predicting\n",
    "y_pred_self = predict(x_test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-76-f0e705dbfb91>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-76-f0e705dbfb91>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    l = {\"ajhfd\", \"kd\",\"s-s\", \"23\", \"a:a\", \"i'm, \">in\"}\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "l = {\"ajhfd\", \"kd\",\"s-s\", \"23\", \"a:a\", \"i'm, \">in\"}\n",
    "for x in l:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject:',\n",
       " 'from:',\n",
       " 'date:',\n",
       " 'newsgroups:',\n",
       " 'message-id:',\n",
       " 'lines:',\n",
       " 'path:',\n",
       " 'article',\n",
       " 'people',\n",
       " 'university',\n",
       " 'know',\n",
       " 'think',\n",
       " \"i'm\",\n",
       " 'distribution:',\n",
       " 'time',\n",
       " 'it.',\n",
       " 'anyone',\n",
       " 'world',\n",
       " 'right',\n",
       " 'believe',\n",
       " 'still',\n",
       " 'something',\n",
       " 'computer',\n",
       " 'system',\n",
       " \"i've\",\n",
       " '15',\n",
       " 'god',\n",
       " 'back',\n",
       " 'news',\n",
       " \"can't\",\n",
       " 'state',\n",
       " 'work',\n",
       " '>in',\n",
       " 'someone',\n",
       " 'government',\n",
       " 'problem',\n",
       " '23',\n",
       " 'another',\n",
       " 'read',\n",
       " 'usa',\n",
       " 'information',\n",
       " '>the',\n",
       " 'number',\n",
       " \"that's\",\n",
       " 'things',\n",
       " 'part',\n",
       " 'fri,',\n",
       " 'point',\n",
       " 'little',\n",
       " '22',\n",
       " 'windows',\n",
       " '>i',\n",
       " 'tue,',\n",
       " 'file',\n",
       " 'data',\n",
       " 'question',\n",
       " 'probably',\n",
       " 'years',\n",
       " 'different',\n",
       " 'available',\n",
       " 'space',\n",
       " '(usenet',\n",
       " 'it,',\n",
       " 'around',\n",
       " 'long',\n",
       " 'tell',\n",
       " 'least',\n",
       " 'best',\n",
       " 'program',\n",
       " 'software',\n",
       " 'public',\n",
       " 'power',\n",
       " 'thu,',\n",
       " 'thing',\n",
       " 'drive',\n",
       " 'run',\n",
       " 'support',\n",
       " 'however,',\n",
       " \"i'd\",\n",
       " '18',\n",
       " 'rather',\n",
       " 'enough',\n",
       " 'case',\n",
       " 'hard',\n",
       " 'keep',\n",
       " 'fact',\n",
       " '25',\n",
       " 'let',\n",
       " 'science',\n",
       " 'called',\n",
       " 'great',\n",
       " '...',\n",
       " 'call',\n",
       " 'looking',\n",
       " 'mon,',\n",
       " 'found',\n",
       " 'real',\n",
       " 'nothing',\n",
       " '26',\n",
       " 'quite',\n",
       " 'seen',\n",
       " 'law',\n",
       " 'whether',\n",
       " 'trying',\n",
       " 'old',\n",
       " 'actually',\n",
       " 'second',\n",
       " 'mean',\n",
       " 'research',\n",
       " 'wed,',\n",
       " 'group',\n",
       " 'ever',\n",
       " 'always',\n",
       " 'heard',\n",
       " 'several',\n",
       " 'bit',\n",
       " 'next',\n",
       " 'message',\n",
       " 'year',\n",
       " 'keywords:',\n",
       " 'reason',\n",
       " 'well,',\n",
       " 'them.',\n",
       " '---',\n",
       " 'access',\n",
       " 'three',\n",
       " 'maybe',\n",
       " 'national',\n",
       " 'getting',\n",
       " 'following',\n",
       " 'key',\n",
       " 'either',\n",
       " 'car',\n",
       " '(the',\n",
       " 'systems',\n",
       " '>|>',\n",
       " 'given',\n",
       " 'thought',\n",
       " 'image',\n",
       " 'list',\n",
       " 'post',\n",
       " 'inc.',\n",
       " 'kind',\n",
       " 'makes',\n",
       " '14',\n",
       " 'jesus',\n",
       " 'human',\n",
       " 'followup-to:',\n",
       " 'means',\n",
       " 'order',\n",
       " 'person',\n",
       " 'day',\n",
       " 'high',\n",
       " '(and',\n",
       " 'game',\n",
       " 'done',\n",
       " 'christian',\n",
       " \"i'll\",\n",
       " 'big',\n",
       " '12',\n",
       " 'end',\n",
       " 'version',\n",
       " 'general',\n",
       " 'system)',\n",
       " 'cannot',\n",
       " 'start',\n",
       " 'line',\n",
       " 'name',\n",
       " 'university,',\n",
       " '\"the',\n",
       " 'based',\n",
       " 'center',\n",
       " 'possible',\n",
       " 'david',\n",
       " '27',\n",
       " '(or',\n",
       " 'etc.',\n",
       " 'evidence',\n",
       " 'life',\n",
       " 'local',\n",
       " 'else',\n",
       " 'card',\n",
       " 'says',\n",
       " 'me.',\n",
       " 'saying',\n",
       " 'team',\n",
       " 'came',\n",
       " 'john',\n",
       " 'gun',\n",
       " 'mr.',\n",
       " 'idea',\n",
       " 'pretty',\n",
       " 'true',\n",
       " '(i',\n",
       " '13',\n",
       " 'so,',\n",
       " 'whole',\n",
       " '11',\n",
       " 'left',\n",
       " 'problems',\n",
       " 'already',\n",
       " 'running',\n",
       " 'told',\n",
       " 'american',\n",
       " 'bad',\n",
       " 'wrote:',\n",
       " 'institute',\n",
       " '30',\n",
       " 'small',\n",
       " 'control',\n",
       " 'change',\n",
       " 'man',\n",
       " 'perhaps',\n",
       " 'large',\n",
       " 'place',\n",
       " 'current',\n",
       " 'window',\n",
       " 'original',\n",
       " 'hope',\n",
       " 'ask',\n",
       " 'word',\n",
       " 'though',\n",
       " 'buy',\n",
       " '(david',\n",
       " \"there's\",\n",
       " 'simply',\n",
       " 'feel',\n",
       " 'others',\n",
       " 'show',\n",
       " 'files',\n",
       " 'remember',\n",
       " 'approved:',\n",
       " 'went',\n",
       " 'ca',\n",
       " 'department',\n",
       " 'almost',\n",
       " 'turkish',\n",
       " 'full',\n",
       " 'mail',\n",
       " 'standard',\n",
       " 'dos',\n",
       " 'book',\n",
       " 'technology',\n",
       " 'yet',\n",
       " 'email',\n",
       " 'mac',\n",
       " 'comes',\n",
       " 'chip',\n",
       " 'is,',\n",
       " 'times',\n",
       " 'opinions',\n",
       " 'april',\n",
       " 'x-newsreader:',\n",
       " 'armenian',\n",
       " 'code',\n",
       " 'pay',\n",
       " 'agree',\n",
       " 'certainly',\n",
       " 'questions',\n",
       " 'making',\n",
       " 'away',\n",
       " ':-)',\n",
       " 'disk',\n",
       " 'open',\n",
       " 'live',\n",
       " 'rec.sport.hockey',\n",
       " 'time.',\n",
       " 'children',\n",
       " 'bill',\n",
       " 'graphics',\n",
       " 'interested',\n",
       " 'started',\n",
       " 'understand',\n",
       " 'now,',\n",
       " 'claim',\n",
       " 'source',\n",
       " 'rights',\n",
       " 'that.',\n",
       " 'me,',\n",
       " 'often',\n",
       " 'phone',\n",
       " 'soc.religion.christian',\n",
       " 'rec.sport.baseball',\n",
       " 'video',\n",
       " 'within',\n",
       " 'care',\n",
       " 'answer',\n",
       " 'everything',\n",
       " 'christian@aramis.rutgers.edu',\n",
       " '1.1',\n",
       " '28',\n",
       " 'israel',\n",
       " 'consider',\n",
       " 'working',\n",
       " 'tried',\n",
       " 'rec.motorcycles',\n",
       " 'private',\n",
       " 'love',\n",
       " 'everyone',\n",
       " 'network',\n",
       " 'health',\n",
       " 'a.',\n",
       " 'this.',\n",
       " 'fbi',\n",
       " 'scsi',\n",
       " 'single',\n",
       " 'works',\n",
       " 'money',\n",
       " \"he's\",\n",
       " 'including',\n",
       " 'e-mail',\n",
       " 'note',\n",
       " 'course,',\n",
       " 'couple',\n",
       " '>:',\n",
       " 'u.s.',\n",
       " 'box',\n",
       " 'talking',\n",
       " 'guess',\n",
       " 'price',\n",
       " 'jews',\n",
       " 'sat,',\n",
       " 'type',\n",
       " 'unless',\n",
       " 'tin',\n",
       " 'jewish',\n",
       " 'wanted',\n",
       " 'took',\n",
       " 'president',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'san',\n",
       " '29',\n",
       " 'play',\n",
       " 'info',\n",
       " 'course',\n",
       " 'you.',\n",
       " 'home',\n",
       " 'sort',\n",
       " '>and',\n",
       " 'color',\n",
       " 'college',\n",
       " 'sun',\n",
       " 'matter',\n",
       " 'major',\n",
       " 'although',\n",
       " 'canada',\n",
       " 'write',\n",
       " 'states',\n",
       " 'likely',\n",
       " 'anybody',\n",
       " 'encryption',\n",
       " 'bible',\n",
       " 'among',\n",
       " '>to',\n",
       " 'important',\n",
       " 'copy',\n",
       " 'sun,',\n",
       " 'provide',\n",
       " 'certain',\n",
       " 'instead',\n",
       " 'white',\n",
       " 'similar',\n",
       " 'cause',\n",
       " 'religious',\n",
       " 'wrong',\n",
       " 'western',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'na',\n",
       " 'also,',\n",
       " 'posting',\n",
       " 'address',\n",
       " 'you,',\n",
       " 'check',\n",
       " 'news)',\n",
       " 'pc',\n",
       " 'saw',\n",
       " 'become',\n",
       " '(john',\n",
       " 'via',\n",
       " \"they're\",\n",
       " 'issue',\n",
       " 'yes,',\n",
       " 'rec.autos',\n",
       " 'alt.atheism',\n",
       " 'israeli',\n",
       " 'speed',\n",
       " 'fire',\n",
       " 'engineering',\n",
       " 'asked',\n",
       " 'per',\n",
       " '>>>',\n",
       " 'user',\n",
       " 'games',\n",
       " 'police',\n",
       " 'machine',\n",
       " 'ftp',\n",
       " 'political',\n",
       " 'that,',\n",
       " '*/',\n",
       " 'taken',\n",
       " 'memory',\n",
       " '_/',\n",
       " 'known',\n",
       " 'this,',\n",
       " 'upon',\n",
       " 'school',\n",
       " 'j.',\n",
       " '(news',\n",
       " 'clear',\n",
       " 'christians',\n",
       " 'stop',\n",
       " 'article-i.d.:',\n",
       " 'sci.electronics',\n",
       " 'black',\n",
       " \"we're\",\n",
       " 'clipper',\n",
       " 'include',\n",
       " 'exactly',\n",
       " 'usually',\n",
       " 'difference',\n",
       " 'it?',\n",
       " 'personal',\n",
       " 'sci.med',\n",
       " 'war',\n",
       " 'win',\n",
       " 'display',\n",
       " 'programs',\n",
       " 'internet:',\n",
       " 'common',\n",
       " 'written',\n",
       " 'server',\n",
       " 'cost',\n",
       " 'church',\n",
       " 'especially',\n",
       " 'days',\n",
       " 'house',\n",
       " 'today',\n",
       " '/*',\n",
       " 'unix',\n",
       " 'goes',\n",
       " 'time,',\n",
       " 'stuff',\n",
       " 'mark',\n",
       " 'medical',\n",
       " 'services',\n",
       " 'them,',\n",
       " 'talk',\n",
       " 'value',\n",
       " 'morality',\n",
       " 'hear',\n",
       " 'according',\n",
       " 'four',\n",
       " 'men',\n",
       " 'ibm',\n",
       " 'mind',\n",
       " 'comp.windows.x',\n",
       " 'reading',\n",
       " 'special',\n",
       " 'uses',\n",
       " 'united',\n",
       " 'due',\n",
       " 'side',\n",
       " 'accept',\n",
       " 'nice',\n",
       " 'expect',\n",
       " 'gets',\n",
       " 'turn',\n",
       " 'top',\n",
       " 'rest',\n",
       " '[version',\n",
       " 'sound',\n",
       " 'history',\n",
       " 'shall',\n",
       " 'early',\n",
       " 'security',\n",
       " 'add',\n",
       " 'apple',\n",
       " 'service',\n",
       " 'moral',\n",
       " 'third',\n",
       " 'again,',\n",
       " 'killed',\n",
       " 'form',\n",
       " 'various',\n",
       " \"let's\",\n",
       " 'armenians',\n",
       " 'light',\n",
       " 'longer',\n",
       " '32',\n",
       " 'area',\n",
       " 'simple',\n",
       " 'low',\n",
       " 'contact',\n",
       " 'religion',\n",
       " 'taking',\n",
       " 'comp.graphics',\n",
       " 'deal',\n",
       " '>of',\n",
       " 'p.',\n",
       " 'all,',\n",
       " 'paul',\n",
       " 'needs',\n",
       " 'here.',\n",
       " '\"i',\n",
       " 'posted',\n",
       " '-0400',\n",
       " 'clinton',\n",
       " 'test',\n",
       " 'no,',\n",
       " 'allow',\n",
       " \"what's\",\n",
       " 'kill',\n",
       " 'sale',\n",
       " 'federal',\n",
       " 'except',\n",
       " 'sci.space',\n",
       " '1.',\n",
       " 'summary:',\n",
       " 'talk.politics.guns',\n",
       " 'assume',\n",
       " 'earth',\n",
       " 'death',\n",
       " 'michael',\n",
       " 'application',\n",
       " 'hockey',\n",
       " 'example,',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'considered',\n",
       " 'previous',\n",
       " 'text',\n",
       " 'argument',\n",
       " 'objective',\n",
       " '**',\n",
       " 'coming',\n",
       " 'hit',\n",
       " 'dept.',\n",
       " 'all.',\n",
       " 'sell',\n",
       " 'international',\n",
       " '(mark',\n",
       " 'discussion',\n",
       " '(michael',\n",
       " 'well.',\n",
       " 'front',\n",
       " 'example',\n",
       " 'speak',\n",
       " 'driver',\n",
       " 'thus',\n",
       " 'lost',\n",
       " 'koresh',\n",
       " 'hell',\n",
       " 'members',\n",
       " 'study',\n",
       " 'needed',\n",
       " 'package',\n",
       " 'particular',\n",
       " 'specific',\n",
       " 'mike',\n",
       " 'later',\n",
       " 'said,',\n",
       " 'willing',\n",
       " 'includes',\n",
       " 'sometimes',\n",
       " 'explain',\n",
       " '2.',\n",
       " 'sense',\n",
       " 'view',\n",
       " 'interesting',\n",
       " 'looks',\n",
       " 'hold',\n",
       " 'press',\n",
       " 'company',\n",
       " 'radio',\n",
       " 'steve',\n",
       " 'women',\n",
       " 'body',\n",
       " 'past',\n",
       " 'one.',\n",
       " 'move',\n",
       " 'division',\n",
       " 'c.',\n",
       " 'guy',\n",
       " 'statement',\n",
       " 'military',\n",
       " 'near',\n",
       " 'texas',\n",
       " 'force',\n",
       " 'position',\n",
       " 'experience',\n",
       " 'easy',\n",
       " 'million',\n",
       " 'behind',\n",
       " 'wants',\n",
       " 'runs',\n",
       " 'years,',\n",
       " 'faith',\n",
       " 'fast',\n",
       " 'monitor',\n",
       " 'sent',\n",
       " 'size',\n",
       " 'players',\n",
       " '>that',\n",
       " '>a',\n",
       " 'fact,',\n",
       " \"god's\",\n",
       " '(was',\n",
       " 'board',\n",
       " 'hardware',\n",
       " 'takes',\n",
       " 'way,',\n",
       " 'whatever',\n",
       " 'build',\n",
       " 'internet',\n",
       " 'red',\n",
       " 'laws',\n",
       " 'happened',\n",
       " 'strong',\n",
       " 'not.',\n",
       " 'doubt',\n",
       " 'computing',\n",
       " 'words',\n",
       " 'system.',\n",
       " 'save',\n",
       " 'asking',\n",
       " 'york',\n",
       " 'worth',\n",
       " 'up.',\n",
       " 'there.',\n",
       " 'higher',\n",
       " 'country',\n",
       " 'total',\n",
       " 'model',\n",
       " 'leave',\n",
       " 'fax:',\n",
       " 'thinking',\n",
       " 'people,',\n",
       " 'recently',\n",
       " 'plus',\n",
       " 'communications',\n",
       " 'd.',\n",
       " 'too.',\n",
       " 'users',\n",
       " 'young',\n",
       " 'numbers',\n",
       " 'ago',\n",
       " 'california',\n",
       " 'books',\n",
       " 'technical',\n",
       " 'out.',\n",
       " 'net',\n",
       " 'level',\n",
       " 'images',\n",
       " 'sci.crypt',\n",
       " 'e.',\n",
       " 'sounds',\n",
       " 'theory',\n",
       " 'say,',\n",
       " 'situation',\n",
       " 'result',\n",
       " 'along',\n",
       " 'insurance',\n",
       " 'in-reply-to:',\n",
       " 'city',\n",
       " 'bought',\n",
       " 'knows',\n",
       " 'm.',\n",
       " 'close',\n",
       " 'truth',\n",
       " 'outside',\n",
       " 'gives',\n",
       " 'effect',\n",
       " 'db',\n",
       " '31',\n",
       " 'ones',\n",
       " 'society',\n",
       " 'groups',\n",
       " 'gave',\n",
       " 'supposed',\n",
       " '50',\n",
       " 'head',\n",
       " 'return',\n",
       " 'james',\n",
       " 'none',\n",
       " '40',\n",
       " 'main',\n",
       " 'complete',\n",
       " 'bike',\n",
       " 'nasa',\n",
       " 'reference',\n",
       " 'looked',\n",
       " '1)',\n",
       " 'r.',\n",
       " 'correct',\n",
       " 'create',\n",
       " 'serial',\n",
       " 'people.',\n",
       " 'legal',\n",
       " 'policy',\n",
       " 'report',\n",
       " 'bus',\n",
       " '>if',\n",
       " 'problem.',\n",
       " '(which',\n",
       " 'guns',\n",
       " 'series',\n",
       " 'anonymous',\n",
       " 'business',\n",
       " 'entire',\n",
       " 'project',\n",
       " 'clearly',\n",
       " 'know,',\n",
       " 'short',\n",
       " 'currently',\n",
       " 'screen',\n",
       " '(robert',\n",
       " 'present',\n",
       " 'therefore',\n",
       " '>is',\n",
       " 'happen',\n",
       " 'act',\n",
       " 'basic',\n",
       " 'cut',\n",
       " 'necessarily',\n",
       " 'north',\n",
       " 'completely',\n",
       " 'gas',\n",
       " 'jpeg',\n",
       " 'dod',\n",
       " 'neither',\n",
       " 'dead',\n",
       " 'design',\n",
       " 'baseball',\n",
       " 'suggest',\n",
       " '(in',\n",
       " 'face',\n",
       " 'months',\n",
       " 'response',\n",
       " 'de',\n",
       " 'involved',\n",
       " 'parts',\n",
       " 'oh',\n",
       " 'christ',\n",
       " '(jim',\n",
       " 'dr.',\n",
       " 'la',\n",
       " 'not,',\n",
       " 'mentioned',\n",
       " '2)',\n",
       " '----------------------------------------------------------------------',\n",
       " 'year.',\n",
       " 'illinois',\n",
       " 'amount',\n",
       " 'quality',\n",
       " 'god.',\n",
       " 'built',\n",
       " 'bring',\n",
       " 'thank',\n",
       " 'living',\n",
       " 'l.',\n",
       " 'error',\n",
       " 'scientific',\n",
       " 'follow',\n",
       " 'drivers',\n",
       " 'league',\n",
       " '>it',\n",
       " 'drug',\n",
       " 'rate',\n",
       " 'edt',\n",
       " 'claims',\n",
       " 'points',\n",
       " 'water',\n",
       " 'now.',\n",
       " 'to:',\n",
       " 'jim',\n",
       " 'batf',\n",
       " 'muslim',\n",
       " '33',\n",
       " 'created',\n",
       " 'out,',\n",
       " '(steve',\n",
       " 's.',\n",
       " 'night',\n",
       " 'digital',\n",
       " 'hedrick@athos.rutgers.edu',\n",
       " 'whose',\n",
       " 'work.',\n",
       " 'future',\n",
       " '>this',\n",
       " '(not',\n",
       " 'job',\n",
       " '----',\n",
       " 'faq',\n",
       " 'lines',\n",
       " 'performance',\n",
       " 'arab',\n",
       " 'media',\n",
       " 'serious',\n",
       " 'output',\n",
       " 'mouse',\n",
       " 'designed',\n",
       " 'russian',\n",
       " 'opinion',\n",
       " 'friend',\n",
       " 'process',\n",
       " 'lots',\n",
       " 'him.',\n",
       " 'originator:',\n",
       " 'peace',\n",
       " 'building',\n",
       " 'development',\n",
       " '(as',\n",
       " 'vs',\n",
       " 'office',\n",
       " 'way.',\n",
       " '>--',\n",
       " 'figure',\n",
       " '||',\n",
       " 'format',\n",
       " 'this?',\n",
       " 'results',\n",
       " '2000',\n",
       " 'manager',\n",
       " 'tape',\n",
       " 'final',\n",
       " 'ii',\n",
       " 'again.',\n",
       " 'section',\n",
       " 'offer',\n",
       " 'basis',\n",
       " '3.',\n",
       " 'page',\n",
       " 'st.',\n",
       " 'player',\n",
       " 'hand',\n",
       " 'land',\n",
       " 'keys',\n",
       " 'toronto',\n",
       " 'ground',\n",
       " '>you',\n",
       " 'no.',\n",
       " 'south',\n",
       " 'wonder',\n",
       " 'recent',\n",
       " 'freedom',\n",
       " '100',\n",
       " 'carry',\n",
       " 'so.',\n",
       " 'child',\n",
       " 'misc.forsale',\n",
       " 'decided',\n",
       " 'commercial',\n",
       " 'god,',\n",
       " 'lead',\n",
       " 'washington',\n",
       " ':)',\n",
       " 'prove',\n",
       " 'individual',\n",
       " 'brought',\n",
       " 'learn',\n",
       " 'robert',\n",
       " 'inside',\n",
       " 'necessary',\n",
       " '***',\n",
       " 'usenet',\n",
       " 'attempt',\n",
       " 'related',\n",
       " 'useful',\n",
       " 'regarding',\n",
       " 'dave',\n",
       " 'w.',\n",
       " 'half',\n",
       " 'population',\n",
       " '35',\n",
       " 'wish',\n",
       " 'period',\n",
       " 'one,',\n",
       " 'chance',\n",
       " 'require',\n",
       " 'ide',\n",
       " 'party',\n",
       " 'physical',\n",
       " 'issues',\n",
       " 'drives',\n",
       " 'tv',\n",
       " 'air',\n",
       " 'technology,',\n",
       " 'mention',\n",
       " 'thanks,',\n",
       " 'univ.',\n",
       " 'mine',\n",
       " 'mode',\n",
       " 'ny',\n",
       " 'normal',\n",
       " 'b.',\n",
       " 'required',\n",
       " 'armenia',\n",
       " 'average',\n",
       " 'together',\n",
       " 'corporation',\n",
       " 'bob',\n",
       " 'there,',\n",
       " 'avoid',\n",
       " 'stated',\n",
       " 'interest',\n",
       " 'extra',\n",
       " 'knowledge',\n",
       " '#>',\n",
       " '$1',\n",
       " 'civil',\n",
       " 'action',\n",
       " 'knew',\n",
       " 'purpose',\n",
       " 'online',\n",
       " 'responsible',\n",
       " 'noise',\n",
       " 'week',\n",
       " 'held',\n",
       " 'reply',\n",
       " 'and,',\n",
       " 'directly',\n",
       " 'easily',\n",
       " 'case,',\n",
       " 'hedrick@geneva.rutgers.edu',\n",
       " 'ways',\n",
       " 'genocide',\n",
       " 'launch',\n",
       " 'included',\n",
       " 'bbs',\n",
       " 'suppose',\n",
       " 'modem',\n",
       " 'talk.politics.mideast',\n",
       " 'protect',\n",
       " 'shot',\n",
       " 'fax',\n",
       " 'reported',\n",
       " 'on.',\n",
       " 'hp',\n",
       " 'greek',\n",
       " 'lack',\n",
       " '34',\n",
       " 'court',\n",
       " 'command',\n",
       " 'across',\n",
       " 'vs.',\n",
       " 'crime',\n",
       " 'algorithm',\n",
       " 'science,',\n",
       " 'allowed',\n",
       " '(frank',\n",
       " 'cases',\n",
       " 'do.',\n",
       " 'object',\n",
       " 'boston',\n",
       " 'reasonable',\n",
       " 'controller',\n",
       " 'appreciated.',\n",
       " 'giving',\n",
       " 'christianity',\n",
       " 'starting',\n",
       " 'blue',\n",
       " 'fine',\n",
       " \"who's\",\n",
       " 'term',\n",
       " 'cover',\n",
       " 'system,',\n",
       " 'generally',\n",
       " 'choice',\n",
       " 'continue',\n",
       " 'happy',\n",
       " 'here,',\n",
       " 'thomas',\n",
       " 'us.',\n",
       " 'applications',\n",
       " 'lord',\n",
       " 'wondering',\n",
       " 'weapons',\n",
       " 'internal',\n",
       " 'belief',\n",
       " '->',\n",
       " 'oil',\n",
       " 'stephanopoulos:',\n",
       " 'field',\n",
       " 'base',\n",
       " 'prevent',\n",
       " 'family',\n",
       " 'wait',\n",
       " 'release',\n",
       " 'know.',\n",
       " 'values',\n",
       " 'reasons',\n",
       " 'difficult',\n",
       " 'worked',\n",
       " 'ideas',\n",
       " 'ram',\n",
       " 'tax',\n",
       " 'meaning',\n",
       " 'caused',\n",
       " 'contains',\n",
       " 'requires',\n",
       " 'shows',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison between Sklearn MultinomialNB() and self implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy for sklearn MultinomialNB() - \", test_score)\n",
    "print(\"Accuracy for self implemented Naive Bayes - \", accuracy_score(y_test, y_pred_self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report Comparison between Sklearn MultinomialNB() and self implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report for sklearn MultinomialNB()\",classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report for self implemented Naive Bayes \",classification_report(y_test, y_pred_self))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
