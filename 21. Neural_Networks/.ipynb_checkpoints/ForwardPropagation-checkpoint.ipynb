{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AND function \n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0,0,0,1]]).T\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "\n",
    "$$ sig(z) = \\frac{1}{1+e^{-z}} $$\n",
    "where,  \n",
    "$$ z = (x_1*w_1 + x_2 * w_2 + ... + x_n * w_n) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative of Sigmoid Function\n",
    "$$ \\frac{d(sig(z))}{dz} = sig(z) * [1 - sig(z)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining derivative of sigmoid function\n",
    "def derivativeSigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation without any hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.53464486],\n",
       "        [ 0.13990193]]), array([ 0.42076711]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialising with random weights\n",
    "\n",
    "weights = 2 * np.random.random((2,1)) - 1\n",
    "bias = 2 * np.random.random(1) - 1\n",
    "learning_rate = 0.1\n",
    "## Multiplying with 2 moves the range from (0,1) to (0,2) \n",
    "## Subtracting 2 from it, moves the range from (0,2) to (-1,1)\n",
    "\n",
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6036668 ],\n",
       "       [ 0.63660733],\n",
       "       [ 0.47156129],\n",
       "       [ 0.50650568]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = X\n",
    "output = sigmoid(np.dot(output0, weights) + bias )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Implementation without any hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative of Error with respect to weight between ith unit of a layer to jth unit of next layer.\n",
    "$$ \\frac{d(Error)}{dw_{ij}} = \\frac{d(Error)}{dO_j} * \\frac{dO_j}{d(input_j)} * \\frac{d(input_j)}{dw_{ij}} $$\n",
    "\n",
    "$$ \\implies  \\frac{d(Error)}{dw_{ij}} = (y_{pred} - y_{actual}) * O_j(1-O_j) * O_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights :  [[ 5.47246921]\n",
      " [ 5.47246922]]\n",
      "Bias :  [-8.3014269]\n",
      "output :  [[  2.48100901e-04]\n",
      " [  5.57792692e-02]\n",
      " [  5.57792687e-02]\n",
      " [  9.33609949e-01]]\n"
     ]
    }
   ],
   "source": [
    "for iter in range(10000):\n",
    "    output0 = X\n",
    "    output = sigmoid(np.dot(output0, weights) + bias )\n",
    "    \n",
    "    first_term = output - Y\n",
    "\n",
    "    input_j = np.dot(output0, weights) + bias\n",
    "    second_term = derivativeSigmoid(input_j)\n",
    "\n",
    "    first_two = first_term * second_term\n",
    "\n",
    "    changes = np.dot(output0.T, first_two)\n",
    "    weights = weights - learning_rate * changes\n",
    "\n",
    "    bias_change = np.sum(first_two)    \n",
    "    bias = bias - learning_rate * bias_change\n",
    "    \n",
    "output = sigmoid(np.dot(X, weights) + bias )\n",
    "print(\"Weights : \",weights)\n",
    "print(\"Bias : \", bias)\n",
    "print(\"output : \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation with 1 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden layer weights\n",
    "wh = 2 * np.random.random((2,2)) - 1\n",
    "\n",
    "# Hidden layer biases\n",
    "bh = 2 * np.random.random((1,2)) - 1\n",
    "\n",
    "# Output Weights\n",
    "wo = 2 * np.random.random((2,1)) - 1\n",
    "\n",
    "# Output Biases\n",
    "bo = 2 * np.random.random((1,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39265954],\n",
       "       [ 0.41346297],\n",
       "       [ 0.39258015],\n",
       "       [ 0.41685322]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = X\n",
    "outputHidden = sigmoid(np.dot(output0, wh) + bh)\n",
    "output = sigmoid(np.dot(outputHidden, wo) + bo)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
